{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вас пригласили на работу в коммерческую компанию, занимающуюся разработкой автоматизированных торговых агентов. Одной из первых ваших задач будет подготовка данных для дальнейшей обработки и построения модели. Пообщавшись с коллегами, вы узнали, что вам предстоит работать с несколькими типами активов: акциями из списка SnP500 и криптовалютами (BTC, ETH, SOL, XRP). Вам планируют поручить краткосрочную и среднесрочную торговлю.\n",
    "\n",
    "\n",
    "Вам предлагается на основе предоставленной информации:\n",
    "\n",
    "\n",
    "1. Создать git-репозиторий, где будет храниться исходный код вашего проекта. Если вы используете приватный репозиторий – дайте преподавателям курса доступ к нему, для возможности проверки ДЗ.\n",
    "2. Добавить файл лицензии, который отражает ваш взгляд на конфиденциальность информации, которую вы подготовите в рамках данного курса.\n",
    "3. Создать код на Python, который загрузит на ваш локальный компьютер данные о котировках ценных бумаг из списка SnP500 и котировки криптовалют (BTC, ETH, SOL, XRP).\n",
    "4. Поскольку вам предстоит много работать с ними в дальнейшем, подготовьте автоматическое отображение графиков текущей ситуации.\n",
    "5. Проверьте нет ли в данных пропусков или ошибок. Проанализируйте выбросы. Оцените, на самом ли деле это выбросы или реальные данные, с которыми предстоит работать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization cell\n",
    "\n",
    "!pip install yfinance -qq\n",
    "import yfinance as yf\n",
    "import pandas_datareader as web\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import zscore\n",
    "\n",
    "\n",
    "# Create Data directory if it doesn't exist\n",
    "dir_stocks = os.path.join('data', 'stock')\n",
    "if not os.path.exists(dir_stocks):\n",
    "    os.makedirs(dir_stocks)\n",
    "dir_crypto = os.path.join('data', 'crypto')\n",
    "if not os.path.exists(dir_crypto):\n",
    "    os.makedirs(dir_crypto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data download to subfolders cell\n",
    "\n",
    "tickers = pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')[0]['Symbol'].str.replace('.','-', regex=True).to_list()[:10]\n",
    "data = yf.download(tickers=tickers,group_by='Ticker',multi_level_index=False,progress=False)\n",
    "data_per_ticker = {}\n",
    "for ticker in tickers:\n",
    "    df = data[ticker]#.dropna()\n",
    "    df.columns = [x.lower() for x in df.columns]\n",
    "    df.index.name = df.index.name.lower()\n",
    "    df.to_csv(os.path.join(dir_stocks, ticker + '.csv'))\n",
    "\n",
    "\n",
    "# Download crypto data\n",
    "cryptos = ['BTC-USD', 'ETH-USD', 'SOL-USD', 'XRP-USD']\n",
    "for crypto in cryptos:\n",
    "    data = yf.download(crypto, multi_level_index=False,progress=False)#.dropna()\n",
    "    df.columns = [x.lower() for x in df.columns]\n",
    "    df.index.name = df.index.name.lower()\n",
    "    data.to_csv(os.path.join(dir_crypto, crypto.split(\"-\")[0] + '.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions definition cell\n",
    "\n",
    "def load_data(ticker: str, is_crypto: bool = False):\n",
    "    df: pd.DataFrame = None\n",
    "    path = dir_stocks\n",
    "    if is_crypto:\n",
    "        path = dir_crypto\n",
    "    path = os.path.join(path, ticker + '.csv')\n",
    "    if os.path.exists(path):\n",
    "        df = pd.read_csv(path, parse_dates=['date'])\n",
    "    else:\n",
    "        print(f'No file for {ticker} at {path}')\n",
    "    return df\n",
    "\n",
    "def plot(df, time_start = None, time_end = None):\n",
    "    if time_start is None:\n",
    "        time_start = min(df['date'])\n",
    "    if time_end is None:\n",
    "        time_end = max(df['date'])\n",
    "    df = df[(df['date'] >= time_start) & (df['date'] <= time_end)]\n",
    "    fig = go.Figure(data=[go.Candlestick(x=df['date'],\n",
    "                open=df['open'],\n",
    "                high=df['high'],\n",
    "                low=df['low'],\n",
    "                close=df['close'])])\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_data_integrity(ticker: str, df:  pd.DataFrame):\n",
    "    # Проверка общего количества пропусков\n",
    "    missing_values = df.isnull().sum()\n",
    "    # Проверка процентного соотношения пропусков\n",
    "    missing_percentage = df.isnull().mean() * 100\n",
    "    print(f'Процентное содержание пропусков для {ticker}: {missing_percentage}')\n",
    "    print(missing_percentage)\n",
    "\n",
    "def z_score(ticker: str, df:  pd.DataFrame):\n",
    "    def z_score_by_field(ticker: str, df: pd.DataFrame, field: str):\n",
    "        z_scores = np.abs(zscore(df[field]))\n",
    "        outliers = df[z_scores > 3]\n",
    "        \n",
    "    for field in ['open', 'high', 'low', 'close']:\n",
    "        z_score_by_field(ticker, df, field)\n",
    "\n",
    "def bounds(ticker: str, df: pd.DataFrame, field: str):\n",
    "    Q1 = df[field].quantile(0.25)\n",
    "    Q3 = df[field].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return lower_bound, upper_bound\n",
    "    \n",
    "def quantile(ticker: str, df:  pd.DataFrame):\n",
    "    def quantile_by_field(ticker: str, df: pd.DataFrame, field: str):\n",
    "        lower_bound, upper_bound = bounds(ticker, df, field)\n",
    "        outliers = df[(df[field] < lower_bound) | (df[field] > upper_bound)]\n",
    "        print(f'outliers for {ticker} {field}: {outliers}')\n",
    "    for field in ['open', 'high', 'low', 'close']:\n",
    "        quantile_by_field(ticker, df, field)\n",
    "   \n",
    "def clean_peaks(ticker: str, df: pd.DataFrame):\n",
    "    def clean_peaks_by_field(ticker: str, df: pd.DataFrame, field: str):\n",
    "        lower_bound, upper_bound = bounds(ticker, df, field)\n",
    "        # Удаление выбросов\n",
    "        df_cleaned = df[(df[field] >= lower_bound) & (df[field] <= upper_bound)]\n",
    "\n",
    "        # Замена выбросов медианой\n",
    "        median_value = df[field].median()\n",
    "        df[field] = np.where((df[field] < lower_bound) | (df[field] > upper_bound), median_value, df[field])\n",
    "    for field in ['open', 'high', 'low', 'close']:\n",
    "        clean_peaks_by_field(ticker, df, field)\n",
    "\n",
    "def remove_high_dispersion(ticker: str, df: pd.DataFrame, threshold: float = 0.1) -> None:\n",
    "    \"\"\"\n",
    "    Remove data points with high dispersion from OHLC data.\n",
    "    High dispersion is defined as (High - Low) / ((High + Low) / 2) > threshold\n",
    "    \n",
    "    Parameters:\n",
    "    threshold (float): Maximum allowed dispersion. Default is 0.1 (10%)\n",
    "    \"\"\"\n",
    "    high_col = f\"{ticker}_high\"\n",
    "    low_col = f\"{ticker}_low\"\n",
    "    if high_col in df.columns and low_col in df.columns:\n",
    "        # Calculate dispersion\n",
    "        dispersion = (df[high_col] - df[low_col]) / ((df[high_col] + df[low_col]) / 2)\n",
    "        # Create mask for valid data points\n",
    "        valid_mask = dispersion <= threshold\n",
    "        # Filter data\n",
    "        df = df[valid_mask]\n",
    "        removed_count = (~valid_mask).sum()\n",
    "        if removed_count > 0:\n",
    "            print(f\"Removed {removed_count} high dispersion points from {ticker}\")\n",
    "\n",
    "def remove_price_anomalies(ticker: str, df: pd.DataFrame, \n",
    "                            z_threshold: float = 3.0, \n",
    "                            window: int = 20) -> None:\n",
    "    \"\"\"\n",
    "    Remove anomalous prices from OHLC data using z-score method.\n",
    "    Points are considered anomalous if they deviate more than z_threshold standard deviations\n",
    "    from the moving average over the specified window.\n",
    "    \n",
    "    Parameters:\n",
    "    z_threshold (float): Number of standard deviations to use as threshold (default: 3.0)\n",
    "    window (int): Window size for moving average calculation (default: 20 periods)\n",
    "    \"\"\"\n",
    "    price_columns = ['open', 'high', 'low', 'close']\n",
    "    ticker_cols = [f\"{ticker}_{col}\" for col in price_columns]\n",
    "    available_cols = [col for col in ticker_cols if col in df.columns]\n",
    "    if not available_cols:\n",
    "        return\n",
    "    # Initialize mask for valid data points\n",
    "    valid_mask = pd.Series(True, index=df.index)\n",
    "    for col in available_cols:\n",
    "        # Calculate rolling mean and standard deviation\n",
    "        rolling_mean = df[col].rolling(window=window, center=True).mean()\n",
    "        rolling_std = df[col].rolling(window=window, center=True).std()\n",
    "        # Calculate z-scores\n",
    "        z_scores = np.abs((df[col] - rolling_mean) / rolling_std)\n",
    "        # Update mask to exclude anomalous points\n",
    "        valid_mask &= (z_scores <= z_threshold)\n",
    "    # Apply the mask to remove anomalous points\n",
    "    removed_count = (~valid_mask).sum()\n",
    "    if removed_count > 0:\n",
    "        df = df[valid_mask]\n",
    "        print(f\"Removed {removed_count} anomalous price points from {ticker}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = 'A'\n",
    "df = load_data(ticker)\n",
    "time_start = pd.to_datetime('2000-01-01')\n",
    "time_end   = pd.to_datetime('2000-01-05')\n",
    "plot(df, time_start, time_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_data_integrity(ticker, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile(ticker, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_score(ticker, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_peaks(ticker, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
